{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "mStpGvEbPhUa"
   },
   "source": [
    "## Preliminary analysis\n",
    "\n",
    "This notebook analyzes the MTA subway data for the week of June 10-17, 2017 that can be found here:\n",
    "\n",
    "http://web.mta.info/developers/turnstile.html\n",
    "\n",
    "1.Download that SAME file and read it in below. View the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "dC6ij1oWPhUb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>EXITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>06/10/2017</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6215258</td>\n",
       "      <td>2104297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>06/10/2017</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6215284</td>\n",
       "      <td>2104303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>06/10/2017</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6215318</td>\n",
       "      <td>2104337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>06/10/2017</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6215475</td>\n",
       "      <td>2104417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>06/10/2017</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6215841</td>\n",
       "      <td>2104465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C/A  UNIT       SCP STATION LINENAME DIVISION        DATE      TIME  \\\n",
       "0  A002  R051  02-00-00   59 ST  NQR456W      BMT  06/10/2017  00:00:00   \n",
       "1  A002  R051  02-00-00   59 ST  NQR456W      BMT  06/10/2017  04:00:00   \n",
       "2  A002  R051  02-00-00   59 ST  NQR456W      BMT  06/10/2017  08:00:00   \n",
       "3  A002  R051  02-00-00   59 ST  NQR456W      BMT  06/10/2017  12:00:00   \n",
       "4  A002  R051  02-00-00   59 ST  NQR456W      BMT  06/10/2017  16:00:00   \n",
       "\n",
       "      DESC  ENTRIES  \\\n",
       "0  REGULAR  6215258   \n",
       "1  REGULAR  6215284   \n",
       "2  REGULAR  6215318   \n",
       "3  REGULAR  6215475   \n",
       "4  REGULAR  6215841   \n",
       "\n",
       "   EXITS                                                                 \n",
       "0                                            2104297                     \n",
       "1                                            2104303                     \n",
       "2                                            2104337                     \n",
       "3                                            2104417                     \n",
       "4                                            2104465                     "
      ]
     },
     "execution_count": 5,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert 1\n",
    "import pandas as pd\n",
    "df = pd.read_csv('turnstile_170617.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "ORJ0mTH0PhUe"
   },
   "source": [
    "2.What are the column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "lI12wZTDPhUf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C/A', 'UNIT', 'SCP', 'STATION', 'LINENAME', 'DIVISION', 'DATE', 'TIME',\n",
       "       'DESC', 'ENTRIES',\n",
       "       'EXITS                                                               '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert 2\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "j5vI0VWzPhUj"
   },
   "source": [
    "3.We can see that there is a lot of whitespace at the end of the exits column name. Let's strip that whitespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "VPkcWYbdPhUk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C/A', 'UNIT', 'SCP', 'STATION', 'LINENAME', 'DIVISION', 'DATE', 'TIME',\n",
       "       'DESC', 'ENTRIES', 'EXITS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert 3\n",
    "df.columns = df.columns.str.strip()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "hpp8WuvNPhUm"
   },
   "source": [
    "4.How big is the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Q8wuU_CRPhUn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197209, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert 4\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "Cs09G8y-PhUp"
   },
   "source": [
    "5.How many unique stations are there? What are they? Answer each of these questions in one line each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "2NYLAovdPhUq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique stations:  376\n",
      "Specifically, they are ['59 ST' '5 AV/59 ST' '57 ST-7 AV' '49 ST' 'TIMES SQ-42 ST'\n",
      " '34 ST-HERALD SQ' '28 ST' '23 ST' '14 ST-UNION SQ' '8 ST-NYU' 'PRINCE ST'\n",
      " 'CANAL ST' 'CITY HALL' 'CORTLANDT ST' 'RECTOR ST' 'WHITEHALL S-FRY'\n",
      " 'DELANCEY/ESSEX' 'BOWERY' 'CHAMBERS ST' 'FULTON ST' 'BROAD ST' '7 AV'\n",
      " 'PARK PLACE' 'BOTANIC GARDEN' 'PROSPECT PARK' 'PARKSIDE AV' 'CHURCH AV'\n",
      " 'BEVERLEY ROAD' 'CORTELYOU RD' 'NEWKIRK PLAZA' 'AVENUE H' 'AVENUE J'\n",
      " 'AVENUE M' 'KINGS HWY' 'AVENUE U' 'NECK RD' 'SHEEPSHEAD BAY'\n",
      " 'BRIGHTON BEACH' 'OCEAN PKWY' 'BOROUGH HALL' 'JAY ST-METROTEC'\n",
      " 'DEKALB AV' 'ATL AV-BARCLAY' 'UNION ST' '4AV-9 ST' '25 ST' '36 ST'\n",
      " '45 ST' '77 ST' '86 ST' 'BAY RIDGE-95 ST' '8 AV' 'FT HAMILTON PKY'\n",
      " 'NEW UTRECHT AV' '18 AV' '20 AV' 'BAY PKWY' '9 AV' '50 ST' '55 ST'\n",
      " '71 ST' '79 ST' '25 AV' 'BAY 50 ST' 'CONEY IS-STILLW' 'W 8 ST-AQUARIUM'\n",
      " '6 AV' '3 AV' '1 AV' 'BEDFORD AV' 'LORIMER ST' 'GRAHAM AV' 'GRAND ST'\n",
      " 'MONTROSE AV' 'MORGAN AV' 'JEFFERSON ST' 'MYRTLE-WYCKOFF' 'HALSEY ST'\n",
      " 'WILSON AV' 'BUSHWICK AV' 'ATLANTIC AV' 'SUTTER AV' 'LIVONIA AV'\n",
      " 'NEW LOTS' 'EAST 105 ST' 'CANARSIE-ROCKAW' 'HOWARD BCH JFK'\n",
      " 'JFK JAMAICA CT1' 'MARCY AV' 'HEWES ST' 'FLUSHING AV' 'MYRTLE AV'\n",
      " 'KOSCIUSZKO ST' 'GATES AV' 'CHAUNCEY ST' 'ALABAMA AV' 'VAN SICLEN AV'\n",
      " 'CLEVELAND ST' 'NORWOOD AV' 'CRESCENT ST' 'CYPRESS HILLS' '75 ST-ELDERTS'\n",
      " '85 ST-FOREST PK' 'WOODHAVEN BLVD' '104 ST' '111 ST' '121 ST'\n",
      " 'CENTRAL AV' 'KNICKERBOCKER' 'SENECA AVE' 'FOREST AVE' 'FRESH POND RD'\n",
      " 'METROPOLITAN AV' 'INWOOD-207 ST' 'DYCKMAN ST' '190 ST' '181 ST' '175 ST'\n",
      " '168 ST' '163 ST-AMSTERDM' '155 ST' '145 ST' '135 ST' '125 ST' '116 ST'\n",
      " 'CATHEDRAL PKWY' '103 ST' '96 ST' '81 ST-MUSEUM' '72 ST' '59 ST COLUMBUS'\n",
      " '42 ST-PORT AUTH' '34 ST-PENN STA' '14 ST' 'W 4 ST-WASH SQ' 'SPRING ST'\n",
      " 'WORLD TRADE CTR' 'HIGH ST' 'HOYT-SCHER' 'LAFAYETTE AV' 'CLINTON-WASH AV'\n",
      " 'FRANKLIN AV' 'NOSTRAND AV' 'KINGSTON-THROOP' 'UTICA AV' 'RALPH AV'\n",
      " 'ROCKAWAY AV' 'BROADWAY JCT' 'LIBERTY AV' 'VAN SICLEN AVE' 'SHEPHERD AV'\n",
      " 'EUCLID AV' 'GRANT AV' '80 ST' '88 ST' 'ROCKAWAY BLVD' 'OZONE PK LEFFRT'\n",
      " 'AQUEDUCT N.COND' 'AQUEDUCT RACETR' 'BROAD CHANNEL' 'BEACH 90 ST'\n",
      " 'BEACH 98 ST' 'BEACH 105 ST' 'ROCKAWAY PARK B' 'BEACH 67 ST'\n",
      " 'BEACH 60 ST' 'BEACH 44 ST' 'BEACH 36 ST' 'BEACH 25 ST' 'FAR ROCKAWAY'\n",
      " '161/YANKEE STAD' '167 ST' '170 ST' '174-175 STS' 'TREMONT AV'\n",
      " '182-183 STS' 'FORDHAM RD' 'KINGSBRIDGE RD' 'BEDFORD PK BLVD'\n",
      " 'NORWOOD 205 ST' '5 AV/53 ST' 'LEXINGTON AV/53' 'COURT SQ-23 ST'\n",
      " 'QUEENS PLAZA' 'STEINWAY ST' '46 ST' 'NORTHERN BLVD' '65 ST'\n",
      " 'JKSN HT-ROOSVLT' 'ELMHURST AV' 'GRAND-NEWTOWN' '63 DR-REGO PARK' '67 AV'\n",
      " 'FOREST HILLS 71' '75 AV' 'KEW GARDENS' 'BRIARWOOD' 'SUTPHIN BLVD'\n",
      " 'PARSONS BLVD' '169 ST' 'JAMAICA 179 ST' 'COURT SQ' '21 ST'\n",
      " 'GREENPOINT AV' 'NASSAU AV' 'BROADWAY' 'MYRTLE-WILLOUGH'\n",
      " 'BEDFORD-NOSTRAN' 'CLASSON AV' '47-50 STS ROCK' '42 ST-BRYANT PK'\n",
      " \"B'WAY-LAFAYETTE\" '2 AV' 'EAST BROADWAY' 'YORK ST' 'BERGEN ST'\n",
      " 'CARROLL ST' 'SMITH-9 ST' '4 AV-9 ST' '15 ST-PROSPECT' 'DITMAS AV'\n",
      " 'AVENUE I' 'AVENUE N' 'AVENUE P' 'AVENUE X' 'NEPTUNE AV' '57 ST'\n",
      " 'LEXINGTON AV/63' 'ROOSEVELT ISLND' '21 ST-QNSBRIDGE' 'JAMAICA VAN WK'\n",
      " 'SUTPHIN-ARCHER' 'JAMAICA CENTER' '72 ST-2 AVE' '86 ST-2 AVE'\n",
      " '96 ST-2 AVE' 'ORCHARD BEACH' 'NEWARK HW BMEBE' 'HARRISON'\n",
      " 'JOURNAL SQUARE' 'GROVE STREET' 'EXCHANGE PLACE' 'PAVONIA/NEWPORT'\n",
      " 'CITY / BUS' 'CHRISTOPHER ST' '9TH STREET' '14TH STREET'\n",
      " 'TWENTY THIRD ST' 'THIRTY ST' 'LACKAWANNA' 'THIRTY THIRD ST'\n",
      " 'NEWARK BM BW' 'NEWARK C' 'NEWARK HM HE' 'PATH WTC 2' 'PATH NEW WTC'\n",
      " 'SOUTH FERRY' 'WALL ST' 'FRANKLIN ST' 'HOUSTON ST' '18 ST'\n",
      " '66 ST-LINCOLN' '116 ST-COLUMBIA' '137 ST CITY COL' '157 ST' '191 ST'\n",
      " '207 ST' '215 ST' 'MARBLE HILL-225' '231 ST' '238 ST' 'V.CORTLANDT PK'\n",
      " 'BOWLING GREEN' 'BROOKLYN BRIDGE' 'BLEECKER ST' 'ASTOR PL' '33 ST'\n",
      " 'GRD CNTRL-42 ST' '51 ST' '68ST-HUNTER CO' '110 ST' '138/GRAND CONC'\n",
      " '149/GRAND CONC' 'MT EDEN AV' '176 ST' 'BURNSIDE AV' '183 ST'\n",
      " 'MOSHOLU PKWY' 'WOODLAWN' 'CENTRAL PK N110' 'HARLEM 148 ST' '3 AV-149 ST'\n",
      " 'JACKSON AV' 'PROSPECT AV' 'INTERVALE AV' 'SIMPSON ST' 'FREEMAN ST'\n",
      " '174 ST' 'WEST FARMS SQ' 'E 180 ST' 'BRONX PARK EAST' 'PELHAM PKWY'\n",
      " 'ALLERTON AV' 'BURKE AV' 'GUN HILL RD' '219 ST' '225 ST' '233 ST'\n",
      " 'NEREID AV' 'WAKEFIELD/241' '3 AV 138 ST' 'BROOK AV' 'CYPRESS AV'\n",
      " \"E 143/ST MARY'S\" 'E 149 ST' 'LONGWOOD AV' 'HUNTS POINT AV' 'WHITLOCK AV'\n",
      " 'ELDER AV' 'MORISN AV/SNDVW' 'ST LAWRENCE AV' 'PARKCHESTER'\n",
      " 'CASTLE HILL AV' 'ZEREGA AV' 'WESTCHESTER SQ' 'MIDDLETOWN RD' 'BUHRE AV'\n",
      " 'PELHAM BAY PARK' '5 AVE' 'VERNON-JACKSON' 'HUNTERS PT AV'\n",
      " 'QUEENSBORO PLZ' '39 AV' '36 AV' '30 AV' 'ASTORIA BLVD' 'ASTORIA DITMARS'\n",
      " '33 ST-RAWSON ST' '40 ST LOWERY ST' '46 ST BLISS ST' '52 ST'\n",
      " '61 ST WOODSIDE' '69 ST' '74 ST-BROADWAY' '82 ST-JACKSON H'\n",
      " '90 ST-ELMHURST' 'JUNCTION BLVD' '103 ST-CORONA' 'METS-WILLETS PT'\n",
      " 'FLUSHING-MAIN' '34 ST-HUDSON YD' 'CLARK ST' 'HOYT ST' 'NEVINS ST'\n",
      " 'GRAND ARMY PLAZ' 'EASTN PKWY-MUSM' 'KINGSTON AV' 'CROWN HTS-UTICA'\n",
      " 'SUTTER AV-RUTLD' 'SARATOGA AV' 'JUNIUS ST' 'PENNSYLVANIA AV'\n",
      " 'NEW LOTS AV' 'PRESIDENT ST' 'STERLING ST' 'WINTHROP ST' 'BEVERLY RD'\n",
      " 'NEWKIRK AV' 'FLATBUSH AV-B.C' 'MORRIS PARK' 'BAYCHESTER AV'\n",
      " 'EASTCHSTER/DYRE' 'ST. GEORGE' 'TOMPKINSVILLE' 'RIT-MANHATTAN'\n",
      " 'RIT-ROOSEVELT']\n"
     ]
    }
   ],
   "source": [
    "#insert 5\n",
    "print(\"Number of unique stations: \", df.STATION.unique().size)\n",
    "print(\"Specifically, they are\", df.STATION.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "cHoomcKyPhUu"
   },
   "source": [
    "6.Okay, so we understand what station represents. But what the heck are C/A, UNIT, and SCP? Keep in mind that in the larger stations, you might have multiple areas within one station that look like this:\n",
    "\n",
    "<img src=\"image.jpg\" style=\"width: 300px;\"/>\n",
    "\n",
    "Further complicating things, there are a few station names like 14TH ST that refer to more than one station location along that street.\n",
    "\n",
    "This data set is not very well documented. Welcome to the joys of real world data science!!!\n",
    "\n",
    "Read the following two links carefully to see other people's confusion and what information they have been able to gather:\n",
    "\n",
    "https://groups.google.com/forum/#!topic/mtadeveloperresources/AMVx2WUY9iI\n",
    "\n",
    "https://groups.google.com/forum/#!searchin/mtadeveloperresources/%22remote$20unit%22%7Csort:relevance/mtadeveloperresources/z8l3ZU9cY6Y/OFlHGkFAimQJ\n",
    "\n",
    "It sounds like each C/A + UNIT + SCP + STATION combo refers to a single turnstile. How many unique turnstiles are there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "zimRzTJMPhUu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C/A    UNIT  SCP       STATION      \n",
       "A002   R051  02-00-00  59 ST            42\n",
       "             02-00-01  59 ST            42\n",
       "             02-03-00  59 ST            42\n",
       "             02-03-01  59 ST            42\n",
       "             02-03-02  59 ST            42\n",
       "             02-03-03  59 ST            42\n",
       "             02-03-04  59 ST            42\n",
       "             02-03-05  59 ST            42\n",
       "             02-03-06  59 ST            42\n",
       "             02-05-00  59 ST            42\n",
       "             02-05-01  59 ST            42\n",
       "             02-06-00  59 ST            42\n",
       "A006   R079  00-00-00  5 AV/59 ST       42\n",
       "             00-00-01  5 AV/59 ST       42\n",
       "             00-00-02  5 AV/59 ST       42\n",
       "             00-00-03  5 AV/59 ST       42\n",
       "             00-00-04  5 AV/59 ST       42\n",
       "             00-03-00  5 AV/59 ST       42\n",
       "             00-03-01  5 AV/59 ST       42\n",
       "             00-03-02  5 AV/59 ST       42\n",
       "A007   R079  01-05-00  5 AV/59 ST       42\n",
       "             01-05-01  5 AV/59 ST       42\n",
       "             01-06-00  5 AV/59 ST       42\n",
       "             01-06-01  5 AV/59 ST       42\n",
       "             01-06-02  5 AV/59 ST       42\n",
       "             01-06-03  5 AV/59 ST       42\n",
       "A010   R080  00-00-00  57 ST-7 AV       42\n",
       "             00-00-01  57 ST-7 AV       42\n",
       "             00-00-02  57 ST-7 AV       42\n",
       "             00-00-03  57 ST-7 AV       42\n",
       "                                        ..\n",
       "S101A  R070  01-00-00  ST. GEORGE       42\n",
       "             01-00-01  ST. GEORGE       42\n",
       "             01-00-02  ST. GEORGE       42\n",
       "             01-00-03  ST. GEORGE       42\n",
       "             01-00-04  ST. GEORGE       42\n",
       "             01-00-05  ST. GEORGE       42\n",
       "             01-00-06  ST. GEORGE       42\n",
       "             01-03-00  ST. GEORGE       42\n",
       "             01-03-01  ST. GEORGE       42\n",
       "             01-03-02  ST. GEORGE       42\n",
       "             01-03-03  ST. GEORGE       42\n",
       "             01-05-00  ST. GEORGE       42\n",
       "             01-05-01  ST. GEORGE       42\n",
       "S102   R165  00-00-00  TOMPKINSVILLE    42\n",
       "             00-00-01  TOMPKINSVILLE    42\n",
       "             00-03-00  TOMPKINSVILLE    42\n",
       "             00-03-01  TOMPKINSVILLE    40\n",
       "             00-03-02  TOMPKINSVILLE    42\n",
       "             00-05-00  TOMPKINSVILLE    42\n",
       "             00-05-01  TOMPKINSVILLE    42\n",
       "TRAM1  R468  00-00-00  RIT-MANHATTAN    42\n",
       "             00-00-01  RIT-MANHATTAN    42\n",
       "             00-00-02  RIT-MANHATTAN    42\n",
       "             00-05-00  RIT-MANHATTAN    42\n",
       "TRAM2  R469  00-00-00  RIT-ROOSEVELT    42\n",
       "             00-00-01  RIT-ROOSEVELT    42\n",
       "             00-03-00  RIT-ROOSEVELT    42\n",
       "             00-03-01  RIT-ROOSEVELT    42\n",
       "             00-05-00  RIT-ROOSEVELT    42\n",
       "             00-05-01  RIT-ROOSEVELT    42\n",
       "Length: 4695, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert 6\n",
    "df.groupby(['C/A', 'UNIT','SCP','STATION']).size()\n",
    "#there're 4695"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "5SJoHrr4PhUx"
   },
   "source": [
    "7.What data types are each of the columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "S1jYB-EUPhUy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 197209 entries, 0 to 197208\n",
      "Data columns (total 11 columns):\n",
      "C/A         197209 non-null object\n",
      "UNIT        197209 non-null object\n",
      "SCP         197209 non-null object\n",
      "STATION     197209 non-null object\n",
      "LINENAME    197209 non-null object\n",
      "DIVISION    197209 non-null object\n",
      "DATE        197209 non-null object\n",
      "TIME        197209 non-null object\n",
      "DESC        197209 non-null object\n",
      "ENTRIES     197209 non-null int64\n",
      "EXITS       197209 non-null int64\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#insert 7\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "gIc54DxNPhU2"
   },
   "source": [
    "8.We can see that the exits and entries are treated as integers but the others are all treated as objects (strings). Overwrite the time column so that it is a datetime object containing the combined date and time column info (so that the times have a chronological order). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "jzIxrOlYPhU3"
   },
   "outputs": [
   ],
   "source": [
    "#insert 8\n",
    "#don't run again ever!!!\n",
    "df['TIME'] = df['DATE'] + \" \" + df['TIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2017-06-10 00:00:00\n",
       "1   2017-06-10 04:00:00\n",
       "2   2017-06-10 08:00:00\n",
       "3   2017-06-10 12:00:00\n",
       "4   2017-06-10 16:00:00\n",
       "Name: TIME, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TIME'] = pd.to_datetime(df['TIME'], format = '%m/%d/%Y %H:%M:%S')\n",
    "df['TIME'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 197209 entries, 0 to 197208\n",
      "Data columns (total 11 columns):\n",
      "C/A         197209 non-null object\n",
      "UNIT        197209 non-null object\n",
      "SCP         197209 non-null object\n",
      "STATION     197209 non-null object\n",
      "LINENAME    197209 non-null object\n",
      "DIVISION    197209 non-null object\n",
      "DATE        197209 non-null object\n",
      "TIME        197209 non-null datetime64[ns]\n",
      "DESC        197209 non-null object\n",
      "ENTRIES     197209 non-null int64\n",
      "EXITS       197209 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(2), object(8)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "_aYeYy02PhU6"
   },
   "source": [
    "9.What is the earliest and latest date in our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "gV_u3A4lPhU6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest Time:  2017-06-10 00:00:00\n",
      "Latest Time:  2017-06-16 21:00:00\n"
     ]
    }
   ],
   "source": [
    "#insert 9\n",
    "print(\"Earliest Time: \", df['TIME'][0])\n",
    "print(\"Latest Time: \", df['TIME'][df['TIME'].size - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "LZT4y83fPhU8"
   },
   "source": [
    "10.If we wanted to only look at the 34st Street Penn Station stop on 6/12/2017, what would we type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "F6LMCUSFPhU9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel/__main__.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Some output was deleted.\n"
     ]
    }
   ],
   "source": [
    "#insert 10\n",
    "\n",
    "#use the following line to locate the name of 34st Street Penn Station stop to be \"34 ST-PENN STA\"\n",
    "#print (df[df['STATION'].str.contains('34')])\n",
    "\n",
    "df.loc[df['STATION'] == \"34 ST-PENN STA\"][df['TIME'] == '6/12/2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df.loc[df['STATION'] == \"14 ST-UNION SQ\"][df['C/A'] == 'A037'][df['UNIT'] == 'R170']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "Nn50RQAgPhU_"
   },
   "source": [
    "11.Create a dictionary called bigDict. It should contain a nested set of keys and values. The outermost key should be the tuple (C/A,UNIT,STATION) and its value should itself be a dictionary with the SCP as the key and a list of (TIME, EXITS) tuples as its values. The purpose of this section is to prepare data for later uses. It should take a little while to finish running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "bigDict = {}\n",
    "\n",
    "#out_key = ('C/A','UNIT','STATION')\n",
    "#in_key = 'SCP'\n",
    "#in_value = (\"TIME\", \"EXITS\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    out_key = (row[\"C/A\"], row[\"UNIT\"], row[\"STATION\"])\n",
    "    in_key = row[\"SCP\"]\n",
    "    in_value = (row[\"TIME\"], row[\"EXITS\"])\n",
    "    \n",
    "    #print(cmd, out_key,\" \", in_key,\" \", in_value)\n",
    "        \n",
    "    #smallDict = {}\n",
    "    #smallDict[in_key] = {}\n",
    "    #smallDict[in_key] = in_value\n",
    "    \n",
    "    #print(smallDict)\n",
    "    \n",
    "    if out_key not in bigDict:\n",
    "        bigDict[out_key] = {}\n",
    "        bigDict[out_key][in_key] = {}\n",
    "        bigDict[out_key][in_key] = [in_value]\n",
    "    else:\n",
    "        if in_key not in bigDict[out_key]:\n",
    "            bigDict[out_key][in_key] = [in_value]\n",
    "        else:\n",
    "            bigDict[out_key][in_key].append(in_value)\n",
    "\n",
    "print(len(bigDict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "qt7jRerOPhVC"
   },
   "source": [
    "12.As an example, use the bigDict to view all of the turnstile data located at the('A037', 'R170', '14 ST-UNION SQ') area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "ZSuarWASPhVC"
   },
   "outputs": [
   ],
   "source": [
    "#insert 12\n",
    "bigDict.get(('A037', 'R170', '14 ST-UNION SQ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "zRotAgYHPhVF"
   },
   "source": [
    "13.Create a function called inspection that takes in the (C/A,UNIT,STATION) tuple and SCP value and plots the exit counter data versus time. \n",
    "\n",
    "For example, the input of \n",
    "```python\n",
    "inspection(('A037', 'R170', '14 ST-UNION SQ'), '05-00-00')\n",
    "```\n",
    "should produce an upward trending plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "GzHd5fJbPhVG"
   },
   "outputs": [
   ],
   "source": [
    "#insert 13\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "#mytuple = (C/A,UNIT,STATION)\n",
    "\n",
    "def inspection(mytuple, SCP):\n",
    "    dates = []\n",
    "    exit_num = []\n",
    "    for tup in bigDict[mytuple][SCP]:\n",
    "        dates.append(tup[0].to_pydatetime())\n",
    "        exit_num.append(tup[1])\n",
    "    plt.plot(dates, exit_num)\n",
    "    plt.show()\n",
    "\n",
    "inspection(('A037', 'R170', '14 ST-UNION SQ'), '05-00-00')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "4PvO-TRJPhVI"
   },
   "source": [
    "## Finding Data Errors\n",
    "14.Due to bugs in MTA data, we will need to remove \"incorrect\" data. First, find the incorrect data by figuring out which turnstile counters aren't going strictly upwards. How many of these incorrect data values are there? Create a smaller dictionary callled \"trouble\" that contains the troublesome data from the bigDict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "xp_22cNoPhVJ"
   },
   "outputs": [
   ],
   "source": [
    "#insert 14\n",
    "trouble = {}\n",
    "incorrect_num = 0\n",
    "\n",
    "def takeSecond(elem):\n",
    "    return elem[1]\n",
    "\n",
    "def upwards(mytuple, SCP):\n",
    "    data = []\n",
    "    for tup in bigDict[mytuple][SCP]:\n",
    "        data.append((tup[0].to_pydatetime(), tup[1]))    \n",
    "    #data.sort(key = takeFirst)\n",
    "    all_up= True\n",
    "    for i in range(len(data) - 1):\n",
    "        #print(takeSecond(data[i]))\n",
    "        if takeSecond(data[i]) > takeSecond(data[i + 1]):\n",
    "            all_up = False\n",
    "    return all_up\n",
    "    \n",
    "for out_key in bigDict.keys():\n",
    "    for in_key in bigDict[out_key].keys():\n",
    "        if(upwards(out_key, in_key) == False):  \n",
    "            incorrect_num = incorrect_num + 1\n",
    "            in_value = bigDict[out_key][in_key]\n",
    "            if out_key not in trouble:\n",
    "                trouble[out_key] = {}\n",
    "                trouble[out_key][in_key] = {}\n",
    "                trouble[out_key][in_key] = in_value\n",
    "            else:\n",
    "                if in_key not in trouble[out_key]:\n",
    "                    trouble[out_key][in_key] = in_value\n",
    "                else:\n",
    "                    trouble[out_key][in_key].append(in_value)\n",
    "print(\"Amount of incorrect num:\", incorrect_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "5ABIdqxlPhVL"
   },
   "source": [
    "15.Using the troublesome dictionary and your inspection plotting function, plot all of the troublesome data. There are several different types of errors. What do you think is causing each type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "dnxCjxB5PhVM"
   },
   "outputs": [
   ],
   "source": [
    "#insert 15\n",
    "n = 0\n",
    "\n",
    "for out_key in trouble:\n",
    "    for in_key in trouble[out_key]:\n",
    "        n = n + 1\n",
    "        print(\"The\", n, \"th troublesome data:\")\n",
    "        inspection(out_key, in_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "ctWRbA6NPhVR"
   },
   "source": [
    "## Data Cleanup\n",
    "There are three types of mistakes: decreasing, garbage values, and turnstile resets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "yYQ1t9ELPhVS"
   },
   "source": [
    "#### Mistake Type I: Monotone but Decreasing - To fix this, we reflect the data. \n",
    "\n",
    "16.Run the cell below to fix it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "RZrRM7QZPhVT",
    "outputId": "6cec83ae-f11c-49a8-d83f-1eebc3812690"
   },
   "outputs": [
   ],
   "source": [
    "def isMonotoneDecrease(mytuple, SCP):\n",
    "    '''Input: Tuple of (Station,SCP). \n",
    "    Output: True if this SCP has monotone property, but decreasing, False otherwise.'''\n",
    "    data = []\n",
    "    for tup in bigDict[mytuple][SCP]:\n",
    "        data.append((tup[0].to_pydatetime(), tup[1]))    \n",
    "    all_up= True\n",
    "    for i in range(len(data) - 1):\n",
    "        if takeSecond(data[i]) < takeSecond(data[i + 1]):\n",
    "            all_up = False\n",
    "    return all_up\n",
    "\n",
    "def fixMonotoneDecrease(mytuple, SCP):\n",
    "    '''reflects the data to fix it'''\n",
    "    n = len(bigDict[mytuple][SCP])\n",
    "    for i in range(n):\n",
    "        bigDict[mytuple][SCP][i] = (bigDict[mytuple][SCP][i][0],(-1)*bigDict[mytuple][SCP][i][1])\n",
    "    \n",
    "\n",
    "monotoneDecreaseList = []\n",
    "for outkey in trouble:\n",
    "    '''Input: Tuple of (Station,SCP). '''\n",
    "    for inkey in trouble[outkey]:\n",
    "        if(isMonotoneDecrease(outkey, inkey)):\n",
    "            tup = (outkey, inkey)\n",
    "            monotoneDecreaseList.append(tup)\n",
    "print(\"Total Monotone Decrease:\",len(monotoneDecreaseList))\n",
    "\n",
    "print(monotoneDecreaseList)\n",
    "\n",
    "for k in monotoneDecreaseList:\n",
    "    fixMonotoneDecrease(k[0], k[1])\n",
    "print(\"Problem Fixed!\")\n",
    "\n",
    "for k in monotoneDecreaseList:\n",
    "    inspection(k[0], k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "rtUwUo-cPhVa"
   },
   "source": [
    "#### Mistake Type II: Garbage Value - To fix this, remove the garbage value\n",
    "\n",
    "17.Run the cell below to fix it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def garbageEliminator(mytuple, SCP):\n",
    "    '''removes nonsensical isolated points'''\n",
    "    n = len(bigDict[mytuple][SCP])\n",
    "    toDel = []\n",
    "    for i in range(1,n-1):\n",
    "        if((bigDict[mytuple][SCP][i-1][1]>bigDict[mytuple][SCP][i+1][1])):\n",
    "            continue\n",
    "        if((bigDict[mytuple][SCP][i-1][1]<=bigDict[mytuple][SCP][i][1]) and (bigDict[mytuple][SCP][i][1]<=bigDict[mytuple][SCP][i+1][1])):\n",
    "            continue\n",
    "        toDel.append(bigDict[mytuple][SCP][i])\n",
    "    #Deletion Process\n",
    "    if(len(toDel)==0):\n",
    "        return 0\n",
    "    for k in toDel:\n",
    "        bigDict[mytuple][SCP].remove(k)\n",
    "    return 1\n",
    "\n",
    "\n",
    "#Driver\n",
    "cnt = 0\n",
    "healList = []\n",
    "for outkey in trouble:\n",
    "    for inkey in trouble[outkey]:\n",
    "        if(garbageEliminator(outkey, inkey)):\n",
    "            tup = (outkey, inkey)\n",
    "            healList.append(tup)\n",
    "print(\"Garbage Removed:\",len(healList))\n",
    "for k in healList:\n",
    "    inspection(k[0], k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "mwwLsrOlPhVd"
   },
   "source": [
    "#### Mistake Type III: Turnstile Reset - To fix this, shift the data upwards.\n",
    "\n",
    "18.Run the cell below to fix it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "_Q9Uvl-APhVd",
    "outputId": "e268af6a-263e-48a8-b44e-e883ba227697"
   },
   "outputs": [
   ],
   "source": [
    "def dealingWithReset(tup):\n",
    "    '''for counters that are reset, we fix the data by shifting it upwards'''\n",
    "    sta = tup[0]\n",
    "    tsl = tup[1]\n",
    "    n = len(bigDict[sta][tsl])\n",
    "    #Detecting Part\n",
    "    resetPoint = [] # it means (i,i+1) is reset\n",
    "    resetSet = []\n",
    "    for i in range(1,n-2):\n",
    "        if(bigDict[sta][tsl][i][1]<=bigDict[sta][tsl][i+1][1]):\n",
    "            continue #We don't need to change this one\n",
    "        resetPoint.append(i)\n",
    "    #Fixing Part\n",
    "    resetSet = set(resetPoint)\n",
    "    cumulative = 0\n",
    "    for i in range(n-2):\n",
    "        if(i not in resetSet):\n",
    "            bigDict[sta][tsl][i] = (bigDict[sta][tsl][i][0],bigDict[sta][tsl][i][1]+cumulative)\n",
    "            continue\n",
    "        #Problem\n",
    "        expected = (bigDict[sta][tsl][i][1]-bigDict[sta][tsl][i-1][1])+ (bigDict[sta][tsl][i+2][1]-bigDict[sta][tsl][i+1][1])\n",
    "        expected = int(expected/2)\n",
    "        shift = (bigDict[sta][tsl][i][1]+expected)-bigDict[sta][tsl][i+1][1]\n",
    "        cumulative = shift\n",
    "    for i in range(n-2,n):\n",
    "        bigDict[sta][tsl][i] = (bigDict[sta][tsl][i][0],bigDict[sta][tsl][i][1]+cumulative)\n",
    "    #Done!\n",
    "    \n",
    "#Test Usage\n",
    "inspection(('JFK03', 'R536', 'JFK JAMAICA CT1'), '00-03-00')\n",
    "dealingWithReset((('JFK03', 'R536', 'JFK JAMAICA CT1'), '00-03-00'))\n",
    "print(\"Cleaned\")\n",
    "inspection(('JFK03', 'R536', 'JFK JAMAICA CT1'), '00-03-00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dealingWithReset(mytuple, SCP):\n",
    "    '''for counters that are reset, we fix the data by shifting it upwards'''\n",
    "    sta = mytuple\n",
    "    tsl = SCP\n",
    "    n = len(bigDict[sta][tsl])\n",
    "    #Detecting Part\n",
    "    resetPoint = [] # it means (i,i+1) is reset\n",
    "    resetSet = []\n",
    "    for i in range(1,n-2):\n",
    "        if(bigDict[sta][tsl][i][1]<=bigDict[sta][tsl][i+1][1]):\n",
    "            continue #We don't need to change this one\n",
    "        resetPoint.append(i)\n",
    "    #Fixing Part\n",
    "    resetSet = set(resetPoint)\n",
    "    cumulative = 0\n",
    "    for i in range(n-2):\n",
    "        if(i not in resetSet):\n",
    "            bigDict[sta][tsl][i] = (bigDict[sta][tsl][i][0],bigDict[sta][tsl][i][1]+cumulative)\n",
    "            continue\n",
    "        #Problem\n",
    "        expected = (bigDict[sta][tsl][i][1]-bigDict[sta][tsl][i-1][1])+ (bigDict[sta][tsl][i+2][1]-bigDict[sta][tsl][i+1][1])\n",
    "        expected = int(expected/2)\n",
    "        shift = (bigDict[sta][tsl][i][1]+expected)-bigDict[sta][tsl][i+1][1]\n",
    "        cumulative = shift\n",
    "    for i in range(n-2,n):\n",
    "        bigDict[sta][tsl][i] = (bigDict[sta][tsl][i][0],bigDict[sta][tsl][i][1]+cumulative)\n",
    "    #Done!\n",
    "    \n",
    "#Test Usage\n",
    "inspection(('JFK03', 'R536', 'JFK JAMAICA CT1'), '00-03-00')\n",
    "dealingWithReset(('JFK03', 'R536', 'JFK JAMAICA CT1'), '00-03-00')\n",
    "print(\"Cleaned\")\n",
    "inspection(('JFK03', 'R536', 'JFK JAMAICA CT1'), '00-03-00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "A4YofuN7PhVh"
   },
   "source": [
    "## Overall Cleaning Process\n",
    "19.This next cell does all of the previous cleanup in one cell. Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "PmQDV_w6PhVi",
    "outputId": "164fc903-a25f-424d-9ea4-541062039093"
   },
   "outputs": [
   ],
   "source": [
    "toClean = {}\n",
    "for st,stv in bigDict.items():\n",
    "    for scp,lst in stv.items():\n",
    "        #Cleaning in Each LIST of turnstile\n",
    "        toDel = []\n",
    "        n = len(lst)\n",
    "        lst.sort()\n",
    "        for i in range(1,n-1):\n",
    "            if(lst[i-1][1]<=lst[i][1] and lst[i][1]<=lst[i+1][1]): #What we expected Data to be (Non-Decreasing)\n",
    "                continue\n",
    "\n",
    "            key = (st,scp)\n",
    "            toClean[key] = trouble.get(key,0)+1\n",
    "            \n",
    "for k in toClean.keys():\n",
    "    print(k)\n",
    "    if(isMonotoneDecrease(k[0], k[1])):\n",
    "        fixMonotoneDecrease(k[0], k[1])\n",
    "    garbageEliminator(k[0], k[1])\n",
    "    dealingWithReset(k[0], k[1])\n",
    "    inspection(k[0], k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "B-eaK9XNPhVk"
   },
   "source": [
    "20.Which troublesome stations are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Bk80qJWkPhVl",
    "outputId": "c61990cc-3de6-4bf0-8312-84dab104d40e"
   },
   "outputs": [
   ],
   "source": [
    "trouble = {}\n",
    "for st,stv in bigDict.items():\n",
    "    for scp,lst in stv.items():\n",
    "        #Cleaning in Each LIST of turnstile\n",
    "        toDel = []\n",
    "        n = len(lst)\n",
    "        lst.sort()\n",
    "        for i in range(1,n-1):\n",
    "            if(lst[i-1][1]<=lst[i][1] and lst[i][1]<=lst[i+1][1]): #What we expected Data to be (Non-Decreasing)\n",
    "                continue\n",
    "                \n",
    "            key = (st,scp)\n",
    "            trouble[key] = trouble.get(key,0)+1\n",
    "print(\"Trouble List: \",len(trouble.keys()))\n",
    "for k,v in trouble.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "3AKy82ddPhVo"
   },
   "source": [
    "21.Delete these two keys from bigDict manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "J-Qbu3zbPhVq"
   },
   "outputs": [
   ],
   "source": [
    "#insert 21\n",
    "del bigDict[('PTH11', 'R545', '14TH STREET')]['00-00-03']\n",
    "del bigDict[('R240', 'R047', 'GRD CNTRL-42 ST')]['00-00-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "mYiZoVzLPhVs"
   },
   "source": [
    "22.The data is now all cleaned, so let's save it so that we don't have to run all of the above code every time. Use the pickle package to save bigDict as an \"MTAdict.pkl\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "BaH-GS-5PhVt"
   },
   "outputs": [
   ],
   "source": [
    "#insert 22\n",
    "import pickle\n",
    "pickle.dump(bigDict, open(\"MTAdict.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "KQeRQaOtPhVw"
   },
   "source": [
    "# --At this point, the data is ready to use and so we are ready for data analysis.--\n",
    "23.Let's read the cleaned data file back in and save it as bigDict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "gll6KAACPhVw"
   },
   "outputs": [
   ],
   "source": [
    "#insert 23\n",
    "import pickle\n",
    "with open('MTAdict.pkl', 'rb') as f:\n",
    "    bigDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "QqgMHi0GPhVy"
   },
   "source": [
    "24.Create a function called turnstileRiders that takes in a single turnstile's date/exit info and a start and endtime (in datetime format) and returns the number of riders through that turnstile within that time period. As an extension, you may want to use a linear approximation in the case of incomplete information. \n",
    "\n",
    "For instance, the input \n",
    "```python\n",
    "t1 = dt.strptime(\"2017-06-12 00:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "t2 = dt.strptime(\"2017-06-13 00:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "turnstileRiders(bigDict[('R204', 'R043', 'WALL ST')][\"02-00-00\"],t1,t2)\n",
    "```\n",
    "\n",
    "should output 1419 riders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "O3WxVxloPhVz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419"
      ]
     },
     "execution_count": 2,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert 24\n",
    "import datetime\n",
    "def turnstileRiders(info,t1,t2): \n",
    "    return int(getNumRider(info, t2) - getNumRider(info, t1))\n",
    "\n",
    "def getNumRider(info, t):\n",
    "    for i in range(len(info) - 1):\n",
    "        if t == info[i][0]:\n",
    "            return int(info[i][1])        \n",
    "        if (info[i][0] < t and t < info[i + 1][0]):\n",
    "            return int(info[i][1] + (info[i + 1][1] - info[i][1]) * ((t - info[i][0])/ (info[i + 1][0] - info[i][0])))\n",
    "    return 0\n",
    "    \n",
    "t1 = datetime.datetime.strptime(\"2017-06-12 00:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "t2 = datetime.datetime.strptime(\"2017-06-13 00:00:00\",\"%Y-%m-%d %H:%M:%S\")\n",
    "turnstileRiders(bigDict[('R204', 'R043', 'WALL ST')][\"02-00-00\"],t1,t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "E25eeOU3PhV2"
   },
   "source": [
    "25.Create a function called stationRiders that calls the turnstileRiders function for each turnstile in a  (C/A,UNIT,STATION) station area and tallies all of the riders through that area between two times.\n",
    "\n",
    "For example, an input of \n",
    "```python\n",
    "getStationRangeRider(bigDict[('R204', 'R043', 'WALL ST')],dt(2017,6,12,0,0,0),dt(2017,6,13,0,0,0))\n",
    "```\n",
    "should output 9507 riders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "FyVMIPztPhV2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9509"
      ]
     },
     "execution_count": 3,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert 25\n",
    "def getStationRangeRider(info_big, t1, t2):\n",
    "    total_rider = 0\n",
    "    for scp in info_big:\n",
    "        total_rider = total_rider + turnstileRiders(info_big[scp], t1, t2)\n",
    "    return total_rider\n",
    "\n",
    "t1 = datetime.datetime(2017,6,12,0,0,0)\n",
    "t2 = datetime.datetime(2017,6,13,0,0,0)\n",
    "getStationRangeRider(bigDict[('R204', 'R043', 'WALL ST')],t1,t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "Q-rMHLJOPhV5"
   },
   "source": [
    "26.There are still several station areas within a station. Make a plot of the day of the week versus the number of total station rider exits for the ENTIRE Wall St station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "3Peae4oHPhV5",
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "#insert 26\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "station = 'WALL ST'\n",
    "dates = pd.date_range(start='6/10/2017 00:00:00', periods = 8)\n",
    "total_sta_num = [0, 0, 0, 0, 0, 0, 0]\n",
    "df_station = df.loc[df['STATION'] == station]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68923, 50098, 158582, 165697, 168078, 164919, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dates) - 2):\n",
    "    df_smll_sta = df_station.loc[df_station['TIME'] == dates[i]]\n",
    "    #print(df_smll_sta['C/A'])\n",
    "    tup1 = []\n",
    "    tup2 = []\n",
    "    for ele in df_smll_sta['C/A']:\n",
    "        tup1.append(ele)\n",
    "    for ele in df_smll_sta['UNIT']:\n",
    "        tup2.append(ele)\n",
    "    for j in range(len(tup1)):\n",
    "        total_sta_num[i] = total_sta_num[i] + getStationRangeRider(bigDict[(tup1[j], tup2[j], station)], dates[i], dates[i + 1])\n",
    "print(total_sta_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/plotting/_converter.py:129: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "6027f3519e1f9f76a513482544d604f75062a3be",
      "text/plain": "<matplotlib.figure.Figure at 0x7f279252b4e0>"
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 408
      }
     }
    }
   ],
   "source": [
    "plt.plot(dates[0:7], total_sta_num[0:7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "OQK29674PhV7"
   },
   "source": [
    "27.Sort by busiest station areas during 6/12 midnight - 6/13 midnight in descending order by creating a list of sorted tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "tw8fwI_BPhV8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Some output was deleted.\n"
     ]
    }
   ],
   "source": [
    "#insert 27\n",
    "import operator\n",
    "\n",
    "busiest_station_area = []\n",
    "info_tuple = {}\n",
    "t1 = datetime.datetime(2017,6,12,0,0,0)\n",
    "t2 = datetime.datetime(2017,6,13,0,0,0)\n",
    "for out_key in bigDict:\n",
    "    info_tuple[out_key] = int(getStationRangeRider(bigDict[out_key],t1,t2))\n",
    "\n",
    "busiest_station_area = sorted(info_tuple.items(), key=operator.itemgetter(1), reverse = True)\n",
    "print(busiest_station_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#each day chronologically corresponds to an element in the list: busiest_top10. Each element consists of a list of top 10 busiest station on the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dates = pd.date_range(start='6/10/2017 00:00:00', periods = 8)\n",
    "\n",
    "busiest_top10 = []\n",
    "\n",
    "for i in range(7):\n",
    "    busiest_station_area = []\n",
    "    info_tuple = {}\n",
    "    t1 = datetime.datetime(2017,6, i + 10,0,0,0)\n",
    "    t2 = datetime.datetime(2017,6, i + 11,0,0,0)\n",
    "    for out_key in bigDict:\n",
    "        info_tuple[out_key] = int(getStationRangeRider(bigDict[out_key],t1,t2))\n",
    "    busiest_station_area = sorted(info_tuple.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    busiest_top10.append(busiest_station_area[:10])\n",
    "print(busiest_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "VDOq0JHPPhV_"
   },
   "source": [
    "28.Make a dictionary called total_dict that contains the station name as its key and the total number of riders through all of its station areas between 6/12-6/13 as its value. Then create a sorted list of tuples to view the busiest stations on that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "96J5DK0ePhWA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('34 ST-PENN STA', 136837), ('GRD CNTRL-42 ST', 135085), ('34 ST-HERALD SQ', 109563), ('TIMES SQ-42 ST', 91048), ('14 ST-UNION SQ', 88416), ('23 ST', 85491), ('FULTON ST', 81130), ('42 ST-PORT AUTH', 72937), ('86 ST', 72800), ('47-50 STS ROCK', 62141), ('125 ST', 58529), ('PATH NEW WTC', 57293), ('59 ST', 57251), ('59 ST COLUMBUS', 55966), ('CANAL ST', 55869), ('CHAMBERS ST', 50766), ('96 ST', 48913), ('14 ST', 47861), ('LEXINGTON AV/53', 47196), ('72 ST', 46476), ('FLUSHING-MAIN', 46095), ('WALL ST', 43674), ('28 ST', 42840), ('42 ST-BRYANT PK', 40872), ('ATL AV-BARCLAY', 39204), ('50 ST', 38847), ('JKSN HT-ROOSVLT', 37885), ('W 4 ST-WASH SQ', 36078), ('7 AV', 35483), ('JAMAICA CENTER', 33735), ('145 ST', 30358), ('BOWLING GREEN', 29966), ('77 ST', 29234), ('BEDFORD AV', 28806), ('5 AV/53 ST', 28603), ('KEW GARDENS', 27568), ('JOURNAL SQUARE', 27394), ('LEXINGTON AV/63', 27153), (\"B'WAY-LAFAYETTE\", 27066), ('CHURCH AV', 27059), ('8 AV', 26274), ('KINGS HWY', 25909), ('GRAND ST', 25459), ('72 ST-2 AVE', 25171), ('BOROUGH HALL', 23761), ('51 ST', 23434), ('33 ST', 23308), ('JAY ST-METROTEC', 23050), ('CROWN HTS-UTICA', 22931), ('1 AV', 22038), ('103 ST', 21692), ('49 ST', 21484), ('181 ST', 20971), ('57 ST-7 AV', 20897), ('PAVONIA/NEWPORT', 20657), ('GROVE STREET', 20579), ('NEWARK HM HE', 20334), ('THIRTY THIRD ST', 20299), ('66 ST-LINCOLN', 20005), ('SUTPHIN-ARCHER', 19693), ('82 ST-JACKSON H', 18568), ('116 ST', 18567), ('JUNCTION BLVD', 18414), ('61 ST WOODSIDE', 18304), ('168 ST', 18285), ('DELANCEY/ESSEX', 17941), ('86 ST-2 AVE', 17737), ('WHITEHALL S-FRY', 17373), ('PARKCHESTER', 17282), ('SOUTH FERRY', 17025), ('EXCHANGE PLACE', 16907), ('CONEY IS-STILLW', 16801), ('ASTOR PL', 16704), ('BROOKLYN BRIDGE', 16578), ('68ST-HUNTER CO', 16482), ('CITY / BUS', 16303), ('NOSTRAND AV', 16249), ('BAY PKWY', 15262), ('2 AV', 15171), ('WOODHAVEN BLVD', 14910), ('ASTORIA DITMARS', 14650), ('103 ST-CORONA', 14623), ('FRANKLIN AV', 14510), ('CORTLANDT ST', 14476), ('FOREST HILLS 71', 14445), ('CHRISTOPHER ST', 14419), ('SPRING ST', 13760), ('167 ST', 13743), ('96 ST-2 AVE', 13666), ('161/YANKEE STAD', 13372), ('SHEEPSHEAD BAY', 13068), ('PRINCE ST', 12844), ('BROADWAY', 12838), ('MYRTLE-WYCKOFF', 12789), ('COURT SQ', 12687), ('UTICA AV', 12603), ('METS-WILLETS PT', 12464), ('57 ST', 12356), ('THIRTY ST', 12108), ('TWENTY THIRD ST', 12072), ('DEKALB AV', 11955), ('LACKAWANNA', 11900), ('VERNON-JACKSON', 11864), ('81 ST-MUSEUM', 11816), ('FLATBUSH AV-B.C', 11666), ('5 AVE', 11622), ('137 ST CITY COL', 11599), ('30 AV', 11570), ('KINGSBRIDGE RD', 11280), ('CATHEDRAL PKWY', 11169), ('34 ST-HUDSON YD', 11082), ('36 ST', 11020), ('8 ST-NYU', 10895), ('GRAND-NEWTOWN', 10873), ('46 ST BLISS ST', 10690), ('111 ST', 10686), ('BRIGHTON BEACH', 10611), ('MARCY AV', 10606), ('170 ST', 10493), ('HIGH ST', 10485), ('5 AV/59 ST', 10377), ('STEINWAY ST', 10357), ('NEWKIRK PLAZA', 10252), ('18 AV', 10125), ('WORLD TRADE CTR', 10075), ('HOUSTON ST', 9929), ('NEVINS ST', 9849), ('33 ST-RAWSON ST', 9842), ('BERGEN ST', 9800), ('79 ST', 9765), ('GUN HILL RD', 9744), ('PROSPECT PARK', 9636), ('191 ST', 9606), ('FT HAMILTON PKY', 9509), ('JAMAICA 179 ST', 9495), ('40 ST LOWERY ST', 9474), ('QUEENS PLAZA', 9366), ('ROCKAWAY AV', 9274), ('HARRISON', 9162), ('METROPOLITAN AV', 9134), ('110 ST', 9037), ('RECTOR ST', 8953), ('NEWARK HW BMEBE', 8879), ('JFK JAMAICA CT1', 8871), ('HOYT-SCHER', 8687), ('3 AV-149 ST', 8632), ('ASTORIA BLVD', 8539), ('HUNTS POINT AV', 8416), ('BROADWAY JCT', 8372), ('FORDHAM RD', 8214), ('135 ST', 8058), ('90 ST-ELMHURST', 8024), ('BEDFORD PK BLVD', 7958), ('PATH WTC 2', 7822), ('4AV-9 ST', 7768), ('CENTRAL PK N110', 7765), ('HALSEY ST', 7710), ('149/GRAND CONC', 7668), ('46 ST', 7556), ('MYRTLE AV', 7544), ('169 ST', 7491), ('175 ST', 7464), ('14TH STREET', 7331), ('157 ST', 7029), ('OZONE PK LEFFRT', 6967), ('21 ST-QNSBRIDGE', 6865), ('116 ST-COLUMBIA', 6841), ('GRAHAM AV', 6778), ('HOYT ST', 6772), ('CASTLE HILL AV', 6677), ('HUNTERS PT AV', 6631), ('ROOSEVELT ISLND', 6565), ('3 AV', 6432), ('52 ST', 6431), ('E 180 ST', 6399), ('AVENUE U', 6336), ('ELDER AV', 6233), ('NORWOOD 205 ST', 6185), ('EAST BROADWAY', 6122), ('GREENPOINT AV', 6119), ('63 DR-REGO PARK', 6095), ('PARSONS BLVD', 6067), ('FRESH POND RD', 5974), ('PELHAM PKWY', 5963), ('TREMONT AV', 5958), ('174 ST', 5914), ('SARATOGA AV', 5913), ('WESTCHESTER SQ', 5901), ('NEW LOTS AV', 5873), ('VAN SICLEN AV', 5831), ('FLUSHING AV', 5756), ('9 AV', 5748), ('CLINTON-WASH AV', 5725), ('NORTHERN BLVD', 5660), ('MORISN AV/SNDVW', 5635), ('69 ST', 5549), ('SMITH-9 ST', 5541), ('4 AV-9 ST', 5536), ('BROOK AV', 5530), ('WAKEFIELD/241', 5469), ('3 AV 138 ST', 5464), ('JAMAICA VAN WK', 5340), ('BLEECKER ST', 5335), ('36 AV', 5277), ('FAR ROCKAWAY', 5258), ('BURNSIDE AV', 5234), ('45 ST', 5192), ('CRESCENT ST', 5059), ('KINGSTON-THROOP', 5043), ('18 ST', 5029), ('GRANT AV', 5027), ('CARROLL ST', 4988), ('PELHAM BAY PARK', 4971), ('NEWKIRK AV', 4965), ('PARK PLACE', 4904), ('CLASSON AV', 4899), ('9TH STREET', 4865), ('NEW LOTS', 4800), ('BEDFORD-NOSTRAN', 4780), ('74 ST-BROADWAY', 4736), ('UNION ST', 4729), ('67 AV', 4645), ('EASTCHSTER/DYRE', 4613), ('YORK ST', 4591), ('E 149 ST', 4477), ('PRESIDENT ST', 4473), ('PARKSIDE AV', 4396), ('QUEENSBORO PLZ', 4370), ('HOWARD BCH JFK', 4343), ('INWOOD-207 ST', 4307), ('DYCKMAN ST', 4278), ('NASSAU AV', 4260), ('25 ST', 4220), ('FREEMAN ST', 4132), ('EASTN PKWY-MUSM', 4057), ('WILSON AV', 4051), ('KINGSTON AV', 4039), ('155 ST', 3944), ('NEW UTRECHT AV', 3923), ('WEST FARMS SQ', 3922), ('CITY HALL', 3921), ('KNICKERBOCKER', 3885), ('MONTROSE AV', 3859), ('MT EDEN AV', 3853), ('15 ST-PROSPECT', 3786), ('ST LAWRENCE AV', 3756), ('EAST 105 ST', 3721), ('BAY RIDGE-95 ST', 3700), ('HARLEM 148 ST', 3637), ('CLARK ST', 3623), ('LORIMER ST', 3572), ('CANARSIE-ROCKAW', 3537), ('BUHRE AV', 3464), ('MORGAN AV', 3438), ('CENTRAL AV', 3430), ('AVENUE J', 3395), ('NORWOOD AV', 3390), ('EUCLID AV', 3322), ('STERLING ST', 3293), ('FRANKLIN ST', 3285), ('176 ST', 3270), ('SUTTER AV', 3229), ('V.CORTLANDT PK', 3226), ('183 ST', 3211), ('W 8 ST-AQUARIUM', 3173), ('CLEVELAND ST', 3171), ('INTERVALE AV', 3160), ('207 ST', 3114), ('LONGWOOD AV', 3013), ('FOREST AVE', 2974), ('AVENUE M', 2941), ('BEVERLEY ROAD', 2922), ('ELMHURST AV', 2905), ('GRAND ARMY PLAZ', 2889), ('BEACH 67 ST', 2888), ('MOSHOLU PKWY', 2866), ('BROAD ST', 2828), ('VAN SICLEN AVE', 2819), ('138/GRAND CONC', 2812), ('BOWERY', 2752), ('RALPH AV', 2752), ('SUTPHIN BLVD', 2736), ('CYPRESS AV', 2706), ('SENECA AVE', 2671), ('65 ST', 2653), ('BRIARWOOD', 2643), ('AVENUE H', 2562), ('COURT SQ-23 ST', 2519), ('MYRTLE-WILLOUGH', 2500), ('GATES AV', 2483), ('ZEREGA AV', 2453), ('80 ST', 2425), ('ALABAMA AV', 2406), ('MORRIS PARK', 2399), ('6 AV', 2381), ('LIVONIA AV', 2332), ('ROCKAWAY BLVD', 2325), ('PROSPECT AV', 2318), ('DITMAS AV', 2280), ('75 ST-ELDERTS', 2270), ('BEACH 25 ST', 2244), ('SIMPSON ST', 2234), ('BOTANIC GARDEN', 2214), ('39 AV', 2188), ('PENNSYLVANIA AV', 2123), ('MIDDLETOWN RD', 2088), ('AVENUE P', 2070), ('ALLERTON AV', 2044), ('CORTELYOU RD', 2036), ('20 AV', 2029), ('WHITLOCK AV', 2028), ('BEACH 60 ST', 2016), ('AVENUE X', 2003), ('174-175 STS', 1970), ('225 ST', 1936), ('190 ST', 1905), ('KOSCIUSZKO ST', 1894), ('AVENUE N', 1892), ('85 ST-FOREST PK', 1888), ('LAFAYETTE AV', 1870), ('71 ST', 1869), ('OCEAN PKWY', 1844), ('21 ST', 1803), ('JEFFERSON ST', 1800), ('AVENUE I', 1777), ('AQUEDUCT N.COND', 1640), ('182-183 STS', 1606), ('WOODLAWN', 1602), ('BEACH 90 ST', 1581), ('SHEPHERD AV', 1579), ('233 ST', 1560), ('WINTHROP ST', 1451), ('231 ST', 1407), ('219 ST', 1395), ('CHAUNCEY ST', 1393), ('ROCKAWAY PARK B', 1381), ('BUSHWICK AV', 1367), ('HEWES ST', 1365), ('LIBERTY AV', 1335), ('MARBLE HILL-225', 1331), ('NEREID AV', 1309), ('163 ST-AMSTERDM', 1302), ('25 AV', 1287), ('NECK RD', 1249), ('BEACH 36 ST', 1203), ('BURKE AV', 1188), ('BEACH 98 ST', 1178), ('88 ST', 1166), ('BRONX PARK EAST', 1140), ('55 ST', 1073), (\"E 143/ST MARY'S\", 1031), ('JACKSON AV', 973), ('75 AV', 938), ('NEWARK BM BW', 915), ('BEACH 44 ST', 875), ('104 ST', 864), ('CYPRESS HILLS', 855), ('215 ST', 850), ('BEVERLY RD', 816), ('ATLANTIC AV', 769), ('BAY 50 ST', 754), ('NEPTUNE AV', 654), ('BAYCHESTER AV', 583), ('BEACH 105 ST', 557), ('AQUEDUCT RACETR', 188), ('121 ST', 147), ('NEWARK C', 147), ('BROAD CHANNEL', 111), ('238 ST', 106), ('RIT-ROOSEVELT', 66), ('RIT-MANHATTAN', 58), ('ORCHARD BEACH', 18), ('SUTTER AV-RUTLD', 0), ('JUNIUS ST', 0), ('ST. GEORGE', 0), ('TOMPKINSVILLE', 0)]\n"
     ]
    }
   ],
   "source": [
    "#insert 28\n",
    "total_dict = {}\n",
    "busiest_station = []\n",
    "for tup in busiest_station_area:\n",
    "    station = tup[0][2]\n",
    "    if station not in total_dict:\n",
    "        total_dict[station] = tup[1]\n",
    "    else:\n",
    "        total_dict[station] = total_dict[station] + tup[1]\n",
    "\n",
    "busiest_station = sorted(total_dict.items(), key=operator.itemgetter(1), reverse = True)\n",
    "print(busiest_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "kB0JnTbePhWB"
   },
   "source": [
    "29.Make a histogram of those station totals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "q4Q7Uzc8PhWC"
   },
   "outputs": [
   ],
   "source": [
    "#insert 29\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stations = []\n",
    "num = []\n",
    "\n",
    "for tup in busiest_station:\n",
    "    stations.append(tup[0])\n",
    "    num.append(tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/6/12 - 2017/6/13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34 ST-PENN STA</th>\n",
       "      <td>136837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRD CNTRL-42 ST</th>\n",
       "      <td>135085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34 ST-HERALD SQ</th>\n",
       "      <td>109563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMES SQ-42 ST</th>\n",
       "      <td>91048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14 ST-UNION SQ</th>\n",
       "      <td>88416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23 ST</th>\n",
       "      <td>85491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FULTON ST</th>\n",
       "      <td>81130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42 ST-PORT AUTH</th>\n",
       "      <td>72937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86 ST</th>\n",
       "      <td>72800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47-50 STS ROCK</th>\n",
       "      <td>62141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125 ST</th>\n",
       "      <td>58529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATH NEW WTC</th>\n",
       "      <td>57293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59 ST</th>\n",
       "      <td>57251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59 ST COLUMBUS</th>\n",
       "      <td>55966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CANAL ST</th>\n",
       "      <td>55869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAMBERS ST</th>\n",
       "      <td>50766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96 ST</th>\n",
       "      <td>48913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14 ST</th>\n",
       "      <td>47861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEXINGTON AV/53</th>\n",
       "      <td>47196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72 ST</th>\n",
       "      <td>46476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLUSHING-MAIN</th>\n",
       "      <td>46095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALL ST</th>\n",
       "      <td>43674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28 ST</th>\n",
       "      <td>42840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42 ST-BRYANT PK</th>\n",
       "      <td>40872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATL AV-BARCLAY</th>\n",
       "      <td>39204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50 ST</th>\n",
       "      <td>38847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JKSN HT-ROOSVLT</th>\n",
       "      <td>37885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W 4 ST-WASH SQ</th>\n",
       "      <td>36078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 AV</th>\n",
       "      <td>35483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAMAICA CENTER</th>\n",
       "      <td>33735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEACH 98 ST</th>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88 ST</th>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRONX PARK EAST</th>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55 ST</th>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E 143/ST MARY'S</th>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JACKSON AV</th>\n",
       "      <td>973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75 AV</th>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEWARK BM BW</th>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEACH 44 ST</th>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104 ST</th>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CYPRESS HILLS</th>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215 ST</th>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEVERLY RD</th>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATLANTIC AV</th>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY 50 ST</th>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEPTUNE AV</th>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAYCHESTER AV</th>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEACH 105 ST</th>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AQUEDUCT RACETR</th>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121 ST</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEWARK C</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROAD CHANNEL</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238 ST</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIT-ROOSEVELT</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIT-MANHATTAN</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORCHARD BEACH</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUTTER AV-RUTLD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUNIUS ST</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST. GEORGE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOMPKINSVILLE</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "34 ST-PENN STA   136837\n",
       "GRD CNTRL-42 ST  135085\n",
       "34 ST-HERALD SQ  109563\n",
       "TIMES SQ-42 ST    91048\n",
       "14 ST-UNION SQ    88416\n",
       "23 ST             85491\n",
       "FULTON ST         81130\n",
       "42 ST-PORT AUTH   72937\n",
       "86 ST             72800\n",
       "47-50 STS ROCK    62141\n",
       "125 ST            58529\n",
       "PATH NEW WTC      57293\n",
       "59 ST             57251\n",
       "59 ST COLUMBUS    55966\n",
       "CANAL ST          55869\n",
       "CHAMBERS ST       50766\n",
       "96 ST             48913\n",
       "14 ST             47861\n",
       "LEXINGTON AV/53   47196\n",
       "72 ST             46476\n",
       "FLUSHING-MAIN     46095\n",
       "WALL ST           43674\n",
       "28 ST             42840\n",
       "42 ST-BRYANT PK   40872\n",
       "ATL AV-BARCLAY    39204\n",
       "50 ST             38847\n",
       "JKSN HT-ROOSVLT   37885\n",
       "W 4 ST-WASH SQ    36078\n",
       "7 AV              35483\n",
       "JAMAICA CENTER    33735\n",
       "...                 ...\n",
       "BEACH 98 ST        1178\n",
       "88 ST              1166\n",
       "BRONX PARK EAST    1140\n",
       "55 ST              1073\n",
       "E 143/ST MARY'S    1031\n",
       "JACKSON AV          973\n",
       "75 AV               938\n",
       "NEWARK BM BW        915\n",
       "BEACH 44 ST         875\n",
       "104 ST              864\n",
       "CYPRESS HILLS       855\n",
       "215 ST              850\n",
       "BEVERLY RD          816\n",
       "ATLANTIC AV         769\n",
       "BAY 50 ST           754\n",
       "NEPTUNE AV          654\n",
       "BAYCHESTER AV       583\n",
       "BEACH 105 ST        557\n",
       "AQUEDUCT RACETR     188\n",
       "121 ST              147\n",
       "NEWARK C            147\n",
       "BROAD CHANNEL       111\n",
       "238 ST              106\n",
       "RIT-ROOSEVELT        66\n",
       "RIT-MANHATTAN        58\n",
       "ORCHARD BEACH        18\n",
       "SUTTER AV-RUTLD       0\n",
       "JUNIUS ST             0\n",
       "ST. GEORGE            0\n",
       "TOMPKINSVILLE         0\n",
       "\n",
       "[376 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_num = pd.DataFrame(num, index = stations)\n",
    "print(\"2017/6/12 - 2017/6/13\")\n",
    "pass_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f278e37e4e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "6200ec3e4f44848d2e6992c2868582da115c7581",
      "text/plain": "<matplotlib.figure.Figure at 0x7f278e3708d0>"
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 401
      }
     }
    }
   ],
   "source": [
    "pass_num[0].plot.hist(rwidth=.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "CtbpBxyRPhWE"
   },
   "source": [
    "30.Create a commuter index to be the average weekday exits divided by the sum of the avg weekday exits + avg weekend exits. To do this, first make a function called isWeekday that returns True if the datetime input is a weekday and False if it isn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "MIHgElRQPhWE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#insert 30\n",
    "import datetime\n",
    "def isWeekday(date):\n",
    "    if date.isoweekday() == 6 or date.isoweekday() == 7:\n",
    "        return False\n",
    "    return True\n",
    "print(isWeekday(datetime.date(2019, 4, 30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "z-07SD3SPhWG"
   },
   "source": [
    "31.Make a function called commuterIndex that inputs a (C/A,UNIT,STATION) tuple and outputs its commuter index. \n",
    "\n",
    "For example, the output of \n",
    "```python\n",
    "getCommuteIndex(('PTH11', 'R545', '14TH STREET'))\n",
    "```\n",
    "should be 0.663."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "JbZfNH0SPhWI"
   },
   "outputs": [
   ],
   "source": [
    "#insert 31\n",
    "dates = pd.date_range(start='6/10/2017 00:00:00', periods = 8)\n",
    "\n",
    "def getCommuteIndex(tup):\n",
    "    weekday_com = 0.0\n",
    "    week_com = 0.0\n",
    "    #print(weekday_com, week_com)\n",
    "\n",
    "    for i in range(6):\n",
    "        num = getStationRangeRider(bigDict[tup], dates[i], dates[i + 1])\n",
    "        if isWeekday(dates[i]):\n",
    "            weekday_com = weekday_com + num\n",
    "            #print(weekday_com)\n",
    "        week_com = week_com + num\n",
    "        #print(week_com)\n",
    "    #print(weekday_com, week_com)\n",
    "    return weekday_com / week_com\n",
    "\n",
    "getCommuteIndex(('PTH11', 'R545', '14TH STREET'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "UQ80WNkhPhWK"
   },
   "source": [
    "32.Create a sorted list of tuples in descending order containing the commuter index and the station area tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Y2Bu9CROPhWK"
   },
   "outputs": [
   ],
   "source": [
    "#insert 32\n",
    "\n",
    "commute_dict = {}\n",
    "commute = []\n",
    "for tup in bigDict:\n",
    "    if tup not in commute_dict:\n",
    "        commute_dict[tup] = getCommuteIndex(tup)\n",
    "    else:\n",
    "        commute_dict[tup] = commute_dict[tup] + getCommuteIndex(tup)\n",
    "\n",
    "commute = sorted(commute_dict.items(), key=operator.itemgetter(1), reverse = True)\n",
    "print(commute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "NsOCaBkdPhWP"
   },
   "source": [
    "33.Remember that there are still several station areas within each station. Let's get all of the commuter indexes for each station area and then take the median of that commuter index to assign to the entire station. Create a sorted list of tuples in descending order containing the median commuter index and the station name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "ep_Wnvf0PhWQ"
   },
   "outputs": [
   ],
   "source": [
    "#insert 33\n",
    "commute_dict_med = {}\n",
    "commute_med = []\n",
    "for tup in bigDict:\n",
    "    if tup not in commute_dict_med:\n",
    "        commute_dict_med[tup] = getCommuteIndex(tup)\n",
    "    else:\n",
    "        commute_dict_med[tup] = commute_dict_med[tup] + getCommuteIndex(tup)\n",
    "\n",
    "commute_med = sorted(commute_dict_med.items(), key=operator.itemgetter(1), reverse = True)\n",
    "print(commute_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "num_tup = []\n",
    "for i in range(21):\n",
    "    num_tup.append((i+1, i + 2, i + 3, i + 4))\n",
    "num_tup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "BrUye94NPhWT"
   },
   "source": [
    "### How can you use what you have done so far to make decisions about MTA advertising???"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Unit 10 - MTA Data Analysis Student Version.ipynb",
   "provenance": [
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}